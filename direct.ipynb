{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Direct Model\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use cuda =  True\n",
      "using device: cuda\n"
     ]
    }
   ],
   "source": [
    "from data_utils import *\n",
    "from train import * \n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "USE_GPU = True\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    \n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "dtype = torch.float32\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "print('use cuda = ', torch.cuda.is_available())\n",
    "print('using device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ItemsViewHDF5(<HDF5 file \"bolete.h5\" (mode r)>)\n",
      "\n",
      "bolete-characteristics (38, 1868)\n",
      "bolete-edibility (5, 1868)\n",
      "bolete-images (3, 512, 512, 1868)\n",
      "bolete-labels (1868,)\n"
     ]
    }
   ],
   "source": [
    "data = load_bolete_data()\n",
    "print()\n",
    "for k in data.keys():\n",
    "    print(k, np.shape(data[k]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test, y_train, y_test = get_train_and_test(data, \"bolete-labels\")\n",
    "\n",
    "N, H, W, C = X_train.shape\n",
    "M = np.size(np.unique(Y_train))\n",
    "\n",
    "Y_train = Y_train.astype(np.long)\n",
    "Y_test = Y_test.astype(np.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_model():\n",
    "    # copy final model from ass igment 2\n",
    "    def flatten(x):\n",
    "        \"\"\"Flattens to [N, -1] where -1 is whatever it needs to be\"\"\"\n",
    "        N = x.shape[0] # read in N, C, H, W\n",
    "        return x.view(N, -1)  \n",
    "        # \"flatten\" the C * H * W values into a single vector per image\n",
    "    class Flatten(nn.Module):\n",
    "        def forward(self, x):\n",
    "            return flatten(x)\n",
    "\n",
    "    channel_1 = 32\n",
    "    channel_2 = 24\n",
    "    channel_3 = 16\n",
    "    hidden_dim = 150\n",
    "    learning_rate = 3e-3 # 1e-2\n",
    "\n",
    "    model = nn.Sequential(\n",
    "        nn.Conv2d(C, channel_1, kernel_size=5, padding=2),\n",
    "        # nn.GroupNorm(4,channel_1),\n",
    "        nn.BatchNorm2d(channel_1),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.3),\n",
    "        nn.Conv2d(channel_1, channel_2, kernel_size=3, padding=1),\n",
    "        # nn.GroupNorm(4,channel_2),\n",
    "        nn.BatchNorm2d(channel_2),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.2),\n",
    "        nn.Conv2d(channel_2, channel_3, kernel_size=3, padding=1),\n",
    "        # nn.GroupNorm(4,channel_3),\n",
    "        nn.BatchNorm2d(channel_3),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.1),\n",
    "        Flatten(),\n",
    "        nn.Linear(channel_3 * H * W, hidden_dim),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(hidden_dim, M)\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "def freeze(model):\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    return model\n",
    "\n",
    "def modified_alexnet():\n",
    "    model = models.alexnet(pretrained=True)\n",
    "    model = freeze(model)\n",
    "\n",
    "    # model.classifier[0] = ???\n",
    "    model.classifier[6] = nn.Linear(in_features=4096, out_features=M, bias=True)\n",
    "    print(model)\n",
    "    return model\n",
    "\n",
    "def modified_googlenet():\n",
    "    model = models.googlenet(pretrained=True)\n",
    "    model = freeze(model)\n",
    "\n",
    "    fc_in_feats = model.fc.in_features\n",
    "    model.fc = nn.Linear(in_features=fc_in_feats, out_features=M, bias=True)\n",
    "    print(model)\n",
    "    return model\n",
    "\n",
    "def modified_resnext():\n",
    "    model = models.resnext101_32x8d(pretrained=True)\n",
    "    model = freeze(model)\n",
    "    \n",
    "    fc_in_feats = model.fc.in_features\n",
    "    model.fc = nn.Linear(fc_in_feats, M)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "def pred_fn(scores):\n",
    "    m = nn.Softmax(dim=1)\n",
    "    return torch.argmax(m(scores), dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validate on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV model on:  cuda\n",
      "CV Fold:  1\n",
      "Training model on:  cuda\n",
      "Iter: 0\n",
      "train Loss: 11.6596 Acc: 0.0031\n",
      "Iter: 1\n",
      "val Loss: 7.1986 Acc: 0.0107\n",
      "Iter: 2\n",
      "train Loss: 6.0528 Acc: 0.0291\n",
      "Iter: 3\n",
      "val Loss: 6.1356 Acc: 0.0071\n",
      "Iter: 4\n",
      "train Loss: 4.8655 Acc: 0.0704\n",
      "Iter: 5\n",
      "val Loss: 6.3362 Acc: 0.0285\n",
      "Iter: 6\n",
      "train Loss: 4.2467 Acc: 0.0873\n",
      "Iter: 7\n",
      "val Loss: 5.4914 Acc: 0.0783\n",
      "Iter: 8\n",
      "train Loss: 3.4461 Acc: 0.1960\n",
      "Iter: 9\n",
      "val Loss: 5.3299 Acc: 0.0498\n",
      "Iter: 10\n",
      "train Loss: 2.8630 Acc: 0.2695\n",
      "Iter: 11\n",
      "val Loss: 5.0432 Acc: 0.0925\n",
      "Iter: 12\n",
      "train Loss: 2.3735 Acc: 0.4028\n",
      "Iter: 13\n",
      "val Loss: 4.8742 Acc: 0.0996\n",
      "Iter: 14\n",
      "train Loss: 1.9589 Acc: 0.5038\n",
      "Iter: 15\n",
      "val Loss: 5.4673 Acc: 0.0854\n",
      "Iter: 16\n",
      "train Loss: 1.6392 Acc: 0.5590\n",
      "Iter: 17\n",
      "val Loss: 5.1771 Acc: 0.0890\n",
      "Iter: 18\n",
      "train Loss: 1.3396 Acc: 0.6784\n",
      "Iter: 19\n",
      "val Loss: 4.8323 Acc: 0.1352\n",
      "Iter: 20\n",
      "train Loss: 1.1336 Acc: 0.7305\n",
      "Iter: 21\n",
      "val Loss: 4.9152 Acc: 0.1388\n",
      "Iter: 22\n",
      "train Loss: 0.9882 Acc: 0.7596\n",
      "Iter: 23\n",
      "val Loss: 5.0166 Acc: 0.1530\n",
      "Iter: 24\n",
      "train Loss: 0.7627 Acc: 0.8331\n",
      "Iter: 25\n",
      "val Loss: 5.3318 Acc: 0.1637\n",
      "Iter: 26\n",
      "train Loss: 0.7092 Acc: 0.8423\n",
      "Iter: 27\n",
      "val Loss: 4.8762 Acc: 0.1851\n",
      "Iter: 28\n",
      "train Loss: 0.5408 Acc: 0.8943\n",
      "Iter: 29\n",
      "val Loss: 4.7540 Acc: 0.1744\n",
      "Iter: 30\n",
      "train Loss: 0.4198 Acc: 0.9020\n",
      "Iter: 31\n",
      "val Loss: 4.8747 Acc: 0.1886\n",
      "Iter: 32\n",
      "train Loss: 0.4604 Acc: 0.8913\n",
      "Iter: 33\n",
      "val Loss: 5.9066 Acc: 0.1281\n",
      "Iter: 34\n",
      "train Loss: 0.4211 Acc: 0.9066\n",
      "Iter: 35\n",
      "val Loss: 5.1019 Acc: 0.1993\n",
      "Iter: 36\n",
      "train Loss: 0.3556 Acc: 0.9142\n",
      "Iter: 37\n",
      "val Loss: 4.5231 Acc: 0.2349\n",
      "Iter: 38\n",
      "train Loss: 0.3086 Acc: 0.9387\n",
      "Iter: 39\n",
      "val Loss: 4.8545 Acc: 0.2171\n",
      "Iter: 40\n",
      "train Loss: 0.2592 Acc: 0.9541\n",
      "Iter: 41\n",
      "val Loss: 5.6347 Acc: 0.1708\n",
      "Iter: 42\n",
      "train Loss: 0.4122 Acc: 0.9020\n",
      "Iter: 43\n",
      "val Loss: 5.7756 Acc: 0.1708\n",
      "Iter: 44\n",
      "train Loss: 0.2038 Acc: 0.9587\n",
      "Iter: 45\n",
      "val Loss: 5.1439 Acc: 0.1993\n",
      "Iter: 46\n",
      "train Loss: 0.2763 Acc: 0.9342\n",
      "Iter: 47\n",
      "val Loss: 5.0920 Acc: 0.2384\n",
      "Iter: 48\n",
      "train Loss: 0.2535 Acc: 0.9342\n",
      "Iter: 49\n",
      "val Loss: 4.7186 Acc: 0.2456\n",
      "Iter: 50\n",
      "train Loss: 0.2125 Acc: 0.9510\n",
      "Iter: 51\n",
      "val Loss: 5.5552 Acc: 0.1922\n",
      "Iter: 52\n",
      "train Loss: 0.2508 Acc: 0.9357\n",
      "Iter: 53\n",
      "val Loss: 5.6110 Acc: 0.2064\n",
      "Iter: 54\n",
      "train Loss: 0.1616 Acc: 0.9632\n",
      "Iter: 55\n",
      "val Loss: 4.9853 Acc: 0.2811\n",
      "Iter: 56\n",
      "train Loss: 0.1603 Acc: 0.9678\n",
      "Iter: 57\n",
      "val Loss: 4.9202 Acc: 0.2527\n",
      "Iter: 58\n",
      "train Loss: 0.1978 Acc: 0.9403\n",
      "Iter: 59\n",
      "val Loss: 5.4851 Acc: 0.2491\n",
      "Iter: 60\n",
      "train Loss: 0.1680 Acc: 0.9587\n",
      "Iter: 61\n",
      "val Loss: 5.2763 Acc: 0.2633\n",
      "Iter: 62\n",
      "train Loss: 0.1884 Acc: 0.9571\n",
      "Iter: 63\n",
      "val Loss: 5.6049 Acc: 0.2064\n",
      "Iter: 64\n",
      "train Loss: 0.0880 Acc: 0.9847\n",
      "Iter: 65\n",
      "val Loss: 5.7940 Acc: 0.2206\n",
      "Iter: 66\n",
      "train Loss: 0.1048 Acc: 0.9709\n",
      "Iter: 67\n",
      "val Loss: 6.3141 Acc: 0.2064\n"
     ]
    }
   ],
   "source": [
    "# model = simple_model()\n",
    "# model = modified_alexnet()\n",
    "# model = modified_googlenet()\n",
    "model = modified_resnext()\n",
    "\n",
    "optimizer = optim.RMSprop(\n",
    "    model.parameters(),\n",
    "    lr=1e-3,\n",
    "    momentum=0.4,\n",
    "    alpha=0.99\n",
    "    )\n",
    "\n",
    "transform = T.Compose([T.ToTensor()])\n",
    "\n",
    "batch_size = 8\n",
    "num_epochs = 90\n",
    "\n",
    "torch.manual_seed(0)\n",
    "history = cross_val(\n",
    "    X_train=X_train,\n",
    "    Y_train=Y_train,\n",
    "    y_train=y_train,\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    loss_fn=loss_fn,\n",
    "    pred_fn=pred_fn,\n",
    "    batch_size=batch_size,\n",
    "    num_epochs=num_epochs,\n",
    "    show_every=1,\n",
    "    folds=1,\n",
    "    test_size=0.3,\n",
    "    device=device,\n",
    "    dtype=dtype,\n",
    "    transform=transform,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=[15,5], sharex=False, sharey=False)\n",
    "axes[0].set_ylabel(\"Loss\")\n",
    "axes[1].set_ylabel(\"Accuracy\")\n",
    "\n",
    "plotnum = 0\n",
    "for a in [\"train\", \"val\"]:\n",
    "    # ax1 = fig.add_subplot(120 + plotnum)\n",
    "    axes[plotnum].set_title(a)\n",
    "    axes[plotnum].set_xlabel(\"Epoch\")\n",
    "    for i in range(len(history[a])):\n",
    "        axes[plotnum].plot(history[a][i])\n",
    "    plotnum += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on all the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = get_loader(X_train, Y_train, batch_size, transform)\n",
    "dataloaders = {\"train\":dataloader}\n",
    "h = train_model(\n",
    "    model,\n",
    "    optimizer,\n",
    "    dataloaders,\n",
    "    loss_fn,\n",
    "    pred_fn,\n",
    "    num_epochs,\n",
    "    show_every=1,\n",
    "    device=device,\n",
    "    dtype=dtype,\n",
    "    phases=[\"train\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, Y, y = X_test, Y_test, y_test\n",
    "X, Y, y = get_val(X_train, Y_train, y_train) # place holder for real test data\n",
    "\n",
    "scores, y_pred, y_true, y_labels = evaluate(\n",
    "    X,  # images\n",
    "    Y,  # output\n",
    "    y,  # labels\n",
    "    model,\n",
    "    M,\n",
    "    pred_fn,\n",
    "    device=device,\n",
    "    transform=None,\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Evaluation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_raw_eval_data(scores, y_pred, y_true, y_labels, \"direct\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check status of GPU Memory for Debugging Purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import gc\n",
    "for obj in gc.get_objects():\n",
    "    try:\n",
    "        if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):\n",
    "            print(type(obj), obj.size())\n",
    "    except:\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.12 64-bit ('cs682': conda)",
   "language": "python",
   "name": "python361264bitcs682conda6c2838d37f0541629036f4dfbc2777db"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
