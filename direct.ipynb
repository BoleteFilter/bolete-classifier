{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python361264bitcs682conda6c2838d37f0541629036f4dfbc2777db",
   "display_name": "Python 3.6.12 64-bit ('cs682': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Direct Model\n",
    "## Setup"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ItemsViewHDF5(<HDF5 file \"bolete.h5\" (mode r)>)\n",
      "\n",
      "bolete-characteristics (38, 1873)\n",
      "bolete-edibility (5, 1873)\n",
      "bolete-images (3, 512, 512, 1873)\n",
      "bolete-labels (1873,)\n"
     ]
    }
   ],
   "source": [
    "from load_data import load_bolete_data, BoleteDataset\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "data = load_bolete_data()\n",
    "print()\n",
    "for k in data.keys():\n",
    "    print(k, np.shape(data[k]))"
   ]
  },
  {
   "source": [
    "## Partition Data\n",
    "Divide data in train and held-out test partitions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sss_tt = StratifiedShuffleSplit(n_splits=1, test_size=0.3, train_size=0.7, random_state=0)\n",
    "X, y = data[\"bolete-images\"].T, data[\"bolete-labels\"].T\n",
    "for train_idx, test_idx in sss_tt.split(X, y):\n",
    "    train_x = X[train_idx]\n",
    "    train_y_sp = data[\"bolete-labels\"].T[train_idx].astype(np.int64)\n",
    "    train_y_ed = data[\"bolete-edibility\"].T[train_idx]\n",
    "    train_y_ch = data[\"bolete-characteristics\"].T[train_idx]\n",
    "\n",
    "    test_x = X[test_idx]\n",
    "    test_y_sp = data[\"bolete-labels\"].T[test_idx].astype(np.int64)\n",
    "    test_y_ed = data[\"bolete-edibility\"].T[test_idx]\n",
    "    test_y_ch = data[\"bolete-characteristics\"].T[test_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of species: 178\nN = 1873, H = 512, W = 512, C = 3\n"
     ]
    }
   ],
   "source": [
    "M = np.size(np.unique(data[\"bolete-labels\"]))\n",
    "N, H, W, C = np.shape(data[\"bolete-images\"].T)\n",
    "print(\"Number of species:\", M)\n",
    "print(\"N = {}, H = {}, W = {}, C = {}\".format(N, H, W, C))"
   ]
  },
  {
   "source": [
    "## Create DataLoader"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = BoleteDataset(train_x, train=True, download=True,\n",
    "                             transform=transform)"
   ]
  },
  {
   "source": [
    "## Setup PyTorch"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "using device: cpu\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "USE_GPU = False\n",
    "dtype = torch.float32 # we will be using float throughout this tutorial\n",
    "# dtype = torch.cuda.FloatTensor\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# Constant to control how frequently we print train loss\n",
    "print_every = 100\n",
    "\n",
    "print('using device:', device)"
   ]
  },
  {
   "source": [
    "## Define models"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_model():\n",
    "    # copy final model from ass igment 2\n",
    "    class Flatten(nn.Module):\n",
    "        def forward(self, x):\n",
    "            return flatten(x)\n",
    "\n",
    "    channel_1 = 32\n",
    "    channel_2 = 24\n",
    "    channel_3 = 16\n",
    "    hidden_dim = 150\n",
    "    torch.manual_seed(0)\n",
    "    learning_rate = 3e-3 # 1e-2\n",
    "\n",
    "    model = nn.Sequential(\n",
    "        nn.Conv2d(C, channel_1, kernel_size=5, padding=2),\n",
    "        # nn.GroupNorm(4,channel_1),\n",
    "        nn.BatchNorm2d(channel_1),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.3),\n",
    "        nn.Conv2d(channel_1, channel_2, kernel_size=3, padding=1),\n",
    "        # nn.GroupNorm(4,channel_2),\n",
    "        nn.BatchNorm2d(channel_2),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.2),\n",
    "        nn.Conv2d(channel_2, channel_3, kernel_size=3, padding=1),\n",
    "        # nn.GroupNorm(4,channel_3),\n",
    "        nn.BatchNorm2d(channel_3),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.1),\n",
    "        Flatten(),\n",
    "        nn.Linear(channel_3 * H * W, hidden_dim),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(hidden_dim, M)\n",
    "    )\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate,\n",
    "                        momentum=0.8, nesterov=True)\n",
    "    return model, optimizer\n"
   ]
  },
  {
   "source": [
    "## Cross Validate on training data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([1048, 512, 512, 3])\ntorch.Size([1048])\ntorch.Size([263, 512, 512, 3])\ntorch.Size([263])\n"
     ]
    }
   ],
   "source": [
    "from train import * \n",
    "\n",
    "folds = 1\n",
    "epochs = 1\n",
    "sss = StratifiedShuffleSplit(n_splits=folds, random_state=0, test_size=0.2, train_size=0.8)\n",
    "\n",
    "for train_index, val_index in sss.split(train_x, train_y_sp):\n",
    "    k_train_x = torch.from_numpy(train_x[train_index])\n",
    "    k_train_y = torch.from_numpy(train_y_sp[train_index])\n",
    "\n",
    "    k_val_x = torch.from_numpy(train_x[val_index])\n",
    "    k_val_y = torch.from_numpy(train_y_sp[val_index])\n",
    "    \n",
    "    print(np.shape(k_train_x), np.shape(k_train_y),\n",
    "          np.shape(k_val_x), np.shape(k_val_y), sep=\"\\n\")\n",
    "\n",
    "    model, optimizer = simple_model()\n",
    "\n",
    "    train_model(\n",
    "        model, \n",
    "        optimizer, \n",
    "        k_train_x, \n",
    "        k_train_y, \n",
    "        k_val_x, \n",
    "        k_val_y, \n",
    "        loss_fcn=F.cross_entropy,\n",
    "        batch_size=32,\n",
    "        epochs=epochs, \n",
    "        device=device,\n",
    "        dtype=dtype\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}