{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python361264bitcs682conda6c2838d37f0541629036f4dfbc2777db",
   "display_name": "Python 3.6.12 64-bit ('cs682': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Direct Model\n",
    "## Setup"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "GPU Available: False\nusing device: cpu\n"
     ]
    }
   ],
   "source": [
    "from data_utils import *\n",
    "from train import * \n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(\"GPU Available:\", use_cuda)\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "print('using device:', device)"
   ]
  },
  {
   "source": [
    "## Load Dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_bolete_data()\n",
    "print()\n",
    "for k in data.keys():\n",
    "    print(k, np.shape(data[k]))"
   ]
  },
  {
   "source": [
    "## Split into train and test"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = get_train_and_test(data, \"bolete-labels\")"
   ]
  },
  {
   "source": [
    "## Define models"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_model():\n",
    "    # copy final model from ass igment 2\n",
    "    class Flatten(nn.Module):\n",
    "        def forward(self, x):\n",
    "            return flatten(x)\n",
    "\n",
    "    channel_1 = 32\n",
    "    channel_2 = 24\n",
    "    channel_3 = 16\n",
    "    hidden_dim = 150\n",
    "    torch.manual_seed(0)\n",
    "    learning_rate = 3e-3 # 1e-2\n",
    "\n",
    "    model = nn.Sequential(\n",
    "        nn.Conv2d(C, channel_1, kernel_size=5, padding=2),\n",
    "        # nn.GroupNorm(4,channel_1),\n",
    "        nn.BatchNorm2d(channel_1),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.3),\n",
    "        nn.Conv2d(channel_1, channel_2, kernel_size=3, padding=1),\n",
    "        # nn.GroupNorm(4,channel_2),\n",
    "        nn.BatchNorm2d(channel_2),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.2),\n",
    "        nn.Conv2d(channel_2, channel_3, kernel_size=3, padding=1),\n",
    "        # nn.GroupNorm(4,channel_3),\n",
    "        nn.BatchNorm2d(channel_3),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.1),\n",
    "        Flatten(),\n",
    "        nn.Linear(channel_3 * H * W, hidden_dim),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(hidden_dim, M)\n",
    "    )\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate,\n",
    "                        momentum=0.8, nesterov=True)\n",
    "    return model, optimizer\n"
   ]
  },
  {
   "source": [
    "## Define the loss function"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "source": [
    "## Cross Validate on training data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([1048, 512, 512, 3])\ntorch.Size([1048])\ntorch.Size([263, 512, 512, 3])\ntorch.Size([263])\n"
     ]
    }
   ],
   "source": [
    "model, optimizer = simple_model()\n",
    "\n",
    "cross_val(X_train,\n",
    "    Y_train,\n",
    "    model,\n",
    "    optimizer,\n",
    "    loss_fn,\n",
    "    batch_size=64,\n",
    "    num_epochs=1,\n",
    "    show_every=5,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}