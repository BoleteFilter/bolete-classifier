{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python361264bitcs682conda6c2838d37f0541629036f4dfbc2777db",
   "display_name": "Python 3.6.12 64-bit ('cs682': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "source": [
    "# Compute Performance Data and Save for Plotting P-Charts"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "characteristic_bolete.h5\n",
      "direct_bolete_lowres.h5\n",
      "direct_bolete.h5\n",
      "characteristic_bolete_lowres.h5\n",
      "direct_ed_bolete_lowres.h5\n",
      "direct_ed_bolete.h5\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "from performance import compute_and_save_performance\n",
    "suffix = \"_true.csv\"\n",
    "for entry in os.listdir(\"evaluation_data\"):\n",
    "    if suffix in entry:\n",
    "        name = entry[:-len(suffix)]\n",
    "        print(name)\n",
    "        compute_and_save_performance(name)"
   ]
  },
  {
   "source": [
    "# Get baselines for p-charts\n",
    "## Random Performance"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Direct:\n",
      "Species\n",
      "Edibility\n",
      "Characteristics:\n",
      "Species\n",
      "=====================================================================================================species done\n",
      "Edibility\n",
      "=====================================================================================================edibility done\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from performance_driver import drive\n",
    "drive(100)"
   ]
  },
  {
   "source": [
    "## Perfect Species Performance"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Species\n",
      "=====================================================================================================done\n",
      "Edibility\n",
      "=====================================================================================================done\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "from performance import perfect_performance\n",
    "print(\"Species\")\n",
    "perfect_performance(\"species\")\n",
    "print(\"Edibility\")\n",
    "perfect_performance(\"edibility\")"
   ]
  },
  {
   "source": [
    "## Compare tau hats"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "========================================================================================================================================================================================================"
     ]
    }
   ],
   "source": [
    "from performance import * \n",
    "from lookalikes import *\n",
    "from data_utils import load_raw_eval_data\n",
    "import os\n",
    "\n",
    "\n",
    "def shared(tau, tau_hat):\n",
    "    return len(np.intersect1d(tau, tau_hat))\n",
    "\n",
    "suffix = \"_true.csv\"\n",
    "entries = os.listdir(\"evaluation_data\")\n",
    "\n",
    "modeltypes = [\"characteristic\", \"direct\"]\n",
    "filetypes = [\"_bolete.h5\", \"_bolete_lowres.h5\"]\n",
    "ps = {filetype:{} for filetype in filetypes}\n",
    "for p in range(100):\n",
    "    p = p/100\n",
    "    tau_hats = {}\n",
    "    for modeltype in modeltypes:\n",
    "        for filetype in filetypes:\n",
    "            name = modeltype+filetype\n",
    "            scores, y_pred, y_true, y_labels = load_raw_eval_data(name)\n",
    "            tau_hats[name] = []\n",
    "            for i in range(len(y_labels)):\n",
    "                if modeltype == \"direct\":\n",
    "                    i_scores = list(enumerate(scores[i]))\n",
    "                    sorted_scores = sorted(i_scores, key=lambda x: x[1], reverse=True)\n",
    "                    size_of_tau_hat = len(lookalikes(sorted_scores[0][0], p))\n",
    "                    tau_hat = [idx for (idx, val) in sorted_scores[:size_of_tau_hat]]\n",
    "                else:\n",
    "                    tau_hat = species_from_feats(y_pred[i], p)\n",
    "                tau_hats[name].append(tau_hat)\n",
    "    \n",
    "    for filetype in filetypes:\n",
    "        tau_hat_char = tau_hats[\"characteristic\"+filetype]\n",
    "        tau_hat_dir = tau_hats[\"direct\"+filetype]\n",
    "        num_examples = len(tau_hat_char)\n",
    "\n",
    "        percent_shared = 0\n",
    "        print(\"=\", end='')\n",
    "        for i in range(num_examples):\n",
    "            total_unique = set(list(tau_hat_char[i]) + list(tau_hat_dir[i]))\n",
    "            total = len(total_unique)\n",
    "            num_shared = shared(tau_hat_char[i], tau_hat_dir[i])\n",
    "            percent_shared += num_shared/total\n",
    "        percent_shared /= num_examples\n",
    "        ps[filetype][p] = round(percent_shared,2)\n",
    "\n",
    "for filetype in filetypes:\n",
    "    p_vals = [val for val in ps[filetype].keys()]\n",
    "    sims = [sim for sim in ps[filetype].values()]\n",
    "    # print('p vals = ', p_vals)\n",
    "    # print('sims = ', sims)\n",
    "    np.savetxt(\"performance_data/\" + filetype[1:] + \"_tau_hat_similarity.csv\", [p_vals, sims], delimiter=\",\", fmt=\"%f\",)"
   ]
  }
 ]
}